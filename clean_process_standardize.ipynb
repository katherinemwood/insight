{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk, datetime, re\n",
    "from nltk.corpus import stopwords\n",
    "from fuzzywuzzy import fuzz, process\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/katherinewood/anaconda3/envs/lexnlp/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Run notebook in conda env lexnlp\n",
    "import lexnlp.extract.en.definitions\n",
    "import lexnlp.extract.en.amounts\n",
    "import lexnlp.extract.en.regulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_all_options(string1, string2):\n",
    "    ratio = fuzz.ratio(string1, string2)\n",
    "    partial_ratio = fuzz.partial_ratio(string1, string2)\n",
    "    token_sort = fuzz.token_sort_ratio(string1, string2)\n",
    "    token_set = fuzz.token_set_ratio(string1, string2)\n",
    "    print(string1 + ', ' + string2 + '\\n' +\n",
    "        'ratio: ' + str(ratio) + '\\n'\n",
    "        'partial_ratio: ' + str(ratio) + '\\n'\n",
    "        'token_sort: ' + str(ratio) + '\\n'\n",
    "        'token_set: ' + str(ratio) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vornado, Vornado LLC\n",
      "ratio: 78\n",
      "partial_ratio: 78\n",
      "token_sort: 78\n",
      "token_set: 78\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_all_options('Vornado', 'Vornado LLC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pd.Series(list(zip(*process.extract('Bosch', ['Bosch', 'BSCH HOME APPLIANCE CORPORATION', 'Vornado Air LLC', '(1/2/3) Bosch: blah blah'])))[1]) > 50).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 0)\n",
    "pd.set_option('display.max_rows', 0)\n",
    "pd.set_option('expand_frame_repr', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls = pd.read_csv('recalls.csv', \n",
    "                      dtype={'RecallID':'Int64', 'RecallNumber': str, 'RecallDate': str,\n",
    "                             'Description': str, 'URL': str, 'Title': str, 'ConsumerContact': str,\n",
    "                             'LastPublishDate': str, 'Images': 'object', 'SoldAtLabel': str,\n",
    "                             'Distributors_CompanyID': 'Int64', 'DistributorsSName': str, \n",
    "                             'Hazards_HazardType': str, 'Hazards_HazardTypeID': str, 'Hazards_Name': str,\n",
    "                             'Importers_CompanyID': 'Int64', 'Importers_Name': str, 'Inconjunctions_URL': str,\n",
    "                             'Injuries_Name': str, 'ManufacturerCountries_Country': str, \n",
    "                             'Manufacturers_CompanyID': 'Int64', 'Manufacturers_Name': str, 'ProductUPCs_UPC': str,\n",
    "                             'Products_CategoryID': 'Int64', 'Products_Description': str, 'Products_Model': str,\n",
    "                             'Products_Name': str, 'Products_NumberOfUnits': str, 'Products_Type': str,\n",
    "                             'Remedies_Name': str, 'RemedyOptions_Option': str, 'Retailers_CompanyID': str,\n",
    "                             'Retailers_Name': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Munge and infill whatever information we can extract from the recall descriptions\n",
    "\n",
    "##UPCs loaded as strings; clean for whitespace & non-numeric chars\n",
    "recalls['ProductUPCs_UPC'] = recalls['ProductUPCs_UPC'].str.replace(' |-|\\.', '')\n",
    "recalls = recalls.rename(columns={'ProductUPCs_UPC': 'UPC'})\n",
    "#Extract unit numbers from string phrases (e.g. \"About 35\")\n",
    "num_units = recalls['Products_NumberOfUnits'].str.replace(',', '')\n",
    "num_units = num_units.str.extract(r'(\\d+)', expand=False).astype('float')\n",
    "recalls['Products_NumberOfUnits'] = num_units\n",
    "#Extract total number of complaints from the string column\n",
    "#Parse dates from strings\n",
    "recalls['RecallDate'] = pd.to_datetime(recalls['RecallDate'])\n",
    "recalls['LastPublishDate'] = pd.to_datetime(recalls['LastPublishDate'])\n",
    "#Break the standardized titles into helpful fields; standardized\n",
    "#titles take the form \"[Company] recalls [product] due to [hazard]\"\n",
    "titles = recalls['Title'].str.split('[Announce]?[s]?Recall[s]?[ed]?|Due to', expand=True)\n",
    "titles = titles.rename(columns={0: 'CompanyShortname', 1: 'ProductsShortname', 2: 'HazardAlt'})\n",
    "recalls = pd.concat([recalls, titles], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorize over a series of strings\n",
    "def extract_probable_specifiers(text):\n",
    "    if pd.isnull(text):\n",
    "        text=''\n",
    "    pattern = r\"(([0-9A-Z])+[a-z]*([\\\\-]?[\\\\.*]?[0-9A-Z]*)*){2,}\"\n",
    "    matches = re.finditer(pattern, text)\n",
    "    unique_matches = set([match.group() for matchNum, match in enumerate(matches)])\n",
    "    return list(unique_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO combine vornado and bosch for a test set\n",
    "reports = v_reports\n",
    "recalls = v_recalls\n",
    "\n",
    "#Funnel match\n",
    "#Preparation: extract possible brands from the fields likely to contain them, for both the reports and the recalls.\n",
    "#Brands may not be referred to by a consistent name across the two datasets.\n",
    "brand_from_comments = [report[1] if not isinstance(report, float) else '' for report in reports['Company Comments'].str.split('\\\\) |:')]\n",
    "reports['candidate_brand'] = list(zip(reports['Brand'], \n",
    "                                           reports['Manufacturer / Importer / Private Labeler Name'],\n",
    "                                           brand_from_comments))\n",
    "recalls['candidate_brand'] = list(zip(recalls['CompanyShortname'], recalls['Manufacturers_Name'],\n",
    "                                     recalls['Distributors_Name'], recalls['Importers_Name']))\n",
    "\n",
    "#Preparation: extract alphanumeric strings that are likely to be model numbers, serial numbers, or UPCs.\n",
    "#Recall notices are very unlikely to have the dedicated fields populated, but tend to mention them in the\n",
    "#text of the recall announcement.\n",
    "#Reports tend to have this information in the dedicated fields, but as a precaution we also try to pull it\n",
    "#from the unstructured text.\n",
    "\n",
    "reports['specifiers'] = [extract_probable_specifiers(report) for report in \n",
    "                         [reports['Product Description'] + ' '+ reports['Incident Description']][0]]\n",
    "\n",
    "recalls['specifiers'] = [extract_probable_specifiers(recall) for recall in recalls['Description']]\n",
    "\n",
    "#Phase 1\n",
    "#For each complaint:\n",
    "#for each candidate brand: 'CompanyShortname', 'Manufacturers_Name', 'Distributors_Name', 'Importers_Name'\n",
    "#fuzzy match to the possible brands list from each recall notice\n",
    "#if any matches score > 50, save recall as candidate (add a column that contains a list of probable recall IDs)\n",
    "#if no matches score > 50, label complaint as \"no recall\"\n",
    "possible_matches = []\n",
    "for i in range(len(reports)):\n",
    "    report = reports.iloc[i, :]\n",
    "    match_ids = []\n",
    "    for c in report['candidate_brand']:\n",
    "        match_ids += [recalls.iloc[r]['RecallID'] for r in range(len(recalls)) if\n",
    "                        (pd.Series(list(zip(*process.extract(c, recalls.iloc[r]['candidate_brand'])))[1]) > 50).any()]\n",
    "    possible_matches.append(list(set(match_ids)))\n",
    "#Phase 2\n",
    "#For all complaints that have candidate recall numbers:\n",
    "#For each candidate recall:\n",
    "#fuzzy match to possible products using product type from report & product name from recall; retain match if score > 50\n",
    "#on any\n",
    "#finally, take the specifiers extracted from the recall description and look for an exact match in the following order:\n",
    "#Model name or number\n",
    "#serial number\n",
    "#UPC\n",
    "#specifiers extracted from the product description\n",
    "#speficiers extracted from incident description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "descs = [extract_probable_specifiers(dsc) for dsc in reports['Incident Description'].sample(n=10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            The Thompsonâ€™s Company \n",
       "1    Boston Warehouse Trading Corp. \n",
       "2                      Libbey Glass \n",
       "3        Thesaurus Global Marketing \n",
       "4            Bosch Thermotechnology \n",
       "5                          Hallmark \n",
       "6                         BCI Burke \n",
       "7                               BMC \n",
       "8                          Toysmith \n",
       "9               Hillsdale Furniture \n",
       "Name: CompanyShortname, dtype: object"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recalls['CompanyShortname'].iloc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = pd.read_csv('SPDB/IncidentReports.csv', encoding=\"ISO-8859-1\", dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matched_brands(brand, reports, recalls):\n",
    "    brand_reports = reports[reports['Manufacturer / Importer / Private Labeler Name'].str.contains(brand, case=False) \n",
    "                            | reports['Brand'].str.contains(brand, case=False)\n",
    "                            | reports['Incident Description'].str.contains(brand, case=False)]\n",
    "    brand_recalls = recalls[recalls['CompanyShortname'].str.contains(brand, case=False) \n",
    "                            | recalls['Manufacturers_Name'].str.contains(brand, case=False) \n",
    "                            | recalls['Importers_Name'].str.contains(brand, case=False) \n",
    "                            | recalls['Distributors_Name'].str.contains(brand, case=False) \n",
    "                            | recalls['Retailers_Name'].str.contains(brand, case=False)]\n",
    "    return (brand_reports, brand_recalls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_reports, v_recalls = get_matched_brands('Vornado', reports, recalls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_reports, b_recalls = get_matched_brands('Bosch', reports, recalls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
